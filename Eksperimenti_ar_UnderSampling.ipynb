{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020_05_13_eksperimenti_ar_UnderSampling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw9d8rIzQKO7",
        "colab_type": "code",
        "outputId": "418d8bad-7c2a-451b-b9cc-58c6b605f9e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "drive.mount('/gdrive')\n",
        "%cd '/gdrive/My Drive/LU/LU DF/8. semestris/Bakalaura Darbs/Datasets'\n",
        "warnings.filterwarnings('ignore')\n",
        "%cd '/gdrive/My Drive/LU/LU DF/8. semestris/Bakalaura Darbs/Datasets'\n",
        "fasttext_data = pd.read_csv('2020_05_09_encoded_Fasttext.csv', index_col=0)\n",
        "print(fasttext_data.shape)\n",
        "base_data = pd.read_csv('papildinatie_jautajumi_cleaned.csv', index_col=0)\n",
        "print(base_data.shape)\n",
        "%cd '/gdrive/My Drive/LU/LU DF/8. semestris/Bakalaura Darbs/Datasets/BERT_encoded'\n",
        "bert_big_data = pd.read_csv('2020_05_10_encoded_BERT_big.csv', index_col=0)\n",
        "bert_multi_cased_data = pd.read_csv('2020_05_10_encoded_BERT_multi_cased.csv', index_col=0)\n",
        "bert_small_2_data = pd.read_csv('2020_05_10_encoded_BERT_small_2.csv', index_col=0)\n",
        "bert_small_data = pd.read_csv('2020_05_10_encoded_BERT_small.csv', index_col=0)\n",
        "print(bert_big_data.shape, bert_multi_cased_data.shape, bert_small_2_data.shape, bert_small_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/LU/LU DF/8. semestris/Bakalaura Darbs/Datasets\n",
            "/gdrive/My Drive/LU/LU DF/8. semestris/Bakalaura Darbs/Datasets\n",
            "(23391, 301)\n",
            "(23391, 2)\n",
            "/gdrive/My Drive/LU/LU DF/8. semestris/Bakalaura Darbs/Datasets/BERT_encoded\n",
            "(23391, 769) (23391, 769) (23391, 257) (23391, 257)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cA8c-rhQsJo",
        "colab_type": "code",
        "outputId": "1bebee80-4266-498e-eab7-bfb8c3cbffba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from keras.preprocessing import text\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import layers\n",
        "from keras import models\n",
        "import datetime\n",
        "from imblearn.under_sampling import ClusterCentroids, NearMiss, RandomUnderSampler\n",
        "from imblearn.base import BaseSampler"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc080_nCRBTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FakeSampler(BaseSampler):\n",
        "    _sampling_type = 'bypass'\n",
        "    def _fit_resample(self, X, y):\n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6MP_oT2XVA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transformResults(results):\n",
        "    mod_results = []\n",
        "    for result in results:\n",
        "        out = np.argmax(result)\n",
        "        mod_results.append(out)\n",
        "    mod_results = np.array(mod_results)  \n",
        "    return mod_results "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cntfoCWhTJxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oversampler  = FakeSampler()\n",
        "indices       = range(3)\n",
        "dataset_list = [bert_small_2_data, bert_small_data, bert_multi_cased_data, bert_big_data, fasttext_data]\n",
        "model_names  = ['BERT small #2', 'BERT small', 'BERT multi cased', 'BERT big', 'FastText']\n",
        "n_split = 5\n",
        "counter = 0 \n",
        "results1 = []\n",
        "header_row = ['Modelis', 'RandomUnderSampler', 'NearMiss', 'ClusterCentroids']\n",
        "results1.append(header_row)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fH-fvVsWS4h",
        "colab_type": "code",
        "outputId": "80defb91-d365-4ebe-ce58-4c47ea2e2581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "exec_start = datetime.datetime.now()\n",
        "for dataset in dataset_list:\n",
        "  result_row = []\n",
        "  result_row.append(model_names[counter])\n",
        "  # Extracting the features and the target based on dimensionality of each dataset\n",
        "  col_count = len(dataset.columns)\n",
        "  features = dataset.iloc[:,:col_count-1]\n",
        "  target = dataset.iloc[:,col_count-1:]\n",
        "\n",
        "  features = features.to_numpy()\n",
        "  target = target.to_numpy()\n",
        "\n",
        "  for i, oversampler in zip( indices, (RandomUnderSampler(),\n",
        "                                       NearMiss(),\n",
        "                                       ClusterCentroids()\n",
        "                                        )):\n",
        "    os_name = oversampler.__class__.__name__\n",
        "    date_start    = datetime.datetime.now()                                     # Fiksējam Oversampling sākuma laiku     \n",
        "    X_res, y_res = oversampler.fit_resample(features, target)                   # Veicam Oversampling\n",
        "    date_end = datetime.datetime.now()                                          # Fiksējam beigu laiku\n",
        "    time_elapsed_us = date_end - date_start                                     # Fiksējam Oversampling patērēto laiku\n",
        "    print('UnderSampled dataset shape:', len(X_res), len(X_res[0]))\n",
        "\n",
        "    model_f1_scores = []\n",
        "    fold_counter = 0\n",
        "    for train_index,test_index in StratifiedKFold(n_split).split(X_res, y_res):\n",
        "      # creating train and test datasets\n",
        "      x_train,x_test=X_res[train_index],X_res[test_index]\n",
        "      y_train,y_test=y_res[train_index],y_res[test_index]  \n",
        "      # Firstly, creating the neural network model\n",
        "      model = models.Sequential()\n",
        "      model.add(layers.Dense(256, activation='relu', input_shape=(col_count-1,)))\n",
        "      model.add(layers.Dense(64, activation='relu'))\n",
        "      model.add(layers.Dense(4, activation='softmax'))\n",
        "      # Then, compiling the created model\n",
        "      model.compile(loss=['sparse_categorical_crossentropy'],\n",
        "                    optimizer='adam',\n",
        "                    metrics=['sparse_categorical_accuracy'])\n",
        "      batch_size = 64\n",
        "      epochs = 5\n",
        "      # Then, fitting the model\n",
        "      history = model.fit(x_train, y_train,\n",
        "                          batch_size=batch_size,\n",
        "                          epochs=epochs,\n",
        "                          verbose=0)\n",
        "      y_pred = model.predict(x_test)                                                  # Prasam modelim paredzēt testa datiem kategorijas\n",
        "      y_pred2 = transformResults(y_pred)                                              # Pārveidojam rezultātus\n",
        "\n",
        "      model_f1_avg = round(f1_score(y_test, y_pred2, average='macro'),4)              # Fiksējam f1 vidējo rezultātu kārtējā K-Foldā\n",
        "      model_f1_scores.append(model_f1_avg)\n",
        "      fold_counter = fold_counter + 1\n",
        "      print('\\tCompleted for model: ',model_names[counter],' K-Fold #', fold_counter, 'F1 score:', model_f1_avg)\n",
        "  \n",
        "    #After the K-Fold validation\n",
        "    model_f1 = round(np.mean(model_f1_scores), 4)\n",
        "    result_row.append(model_f1)\n",
        "    print('Completed for:', os_name,' with F1 score:',model_f1, ' Oversampling duration:',time_elapsed_us)  \n",
        "  #After all four UnderSamplers\n",
        "  results1.append(result_row)\n",
        "  print('Completed for ', model_names[counter], ' with results=', result_row)\n",
        "  counter = counter + 1\n",
        "\n",
        "#In the very end - fix the execution time\n",
        "exec_end = datetime.datetime.now()\n",
        "exec_elapsed = exec_end - exec_start\n",
        "print('Total time elapsed:', exec_elapsed)\n",
        "\n",
        "# Saglabājam visus rezultātus\n",
        "result_data = pd.DataFrame(results1[1:], columns=results1[0])\n",
        "result_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UnderSampled dataset shape: 488 256\n",
            "\tCompleted for model:  BERT small #2  K-Fold # 1 F1 score: 0.6419\n",
            "\tCompleted for model:  BERT small #2  K-Fold # 2 F1 score: 0.5538\n",
            "\tCompleted for model:  BERT small #2  K-Fold # 3 F1 score: 0.7439\n",
            "\tCompleted for model:  BERT small #2  K-Fold # 4 F1 score: 0.558\n",
            "\tCompleted for model:  BERT small #2  K-Fold # 5 F1 score: 0.6494\n",
            "Completed for: RandomUnderSampler  with F1 score: 0.6294  Oversampling duration: 0:00:00.011460\n",
            "UnderSampled dataset shape: 488 256\n",
            "\tCompleted for model:  BERT small #2  K-Fold # 1 F1 score: 0.4374\n",
            "\tCompleted for model:  BERT small #2  K-Fold # 2 F1 score: 0.5959\n",
            "\tCompleted for model:  BERT small #2  K-Fold # 3 F1 score: 0.7781\n",
            "\tCompleted for model:  BERT small #2  K-Fold # 4 F1 score: 0.8254\n",
            "\tCompleted for model:  BERT small #2  K-Fold # 5 F1 score: 0.741\n",
            "Completed for: NearMiss  with F1 score: 0.6756  Oversampling duration: 0:00:01.794017\n",
            "UnderSampled dataset shape: 488 256\n",
            "\tCompleted for model:  BERT small #2  K-Fold # 1 F1 score: 0.5949\n",
            "\tCompleted for model:  BERT small #2  K-Fold # 2 F1 score: 0.594\n",
            "\tCompleted for model:  BERT small #2  K-Fold # 3 F1 score: 0.7123\n",
            "\tCompleted for model:  BERT small #2  K-Fold # 4 F1 score: 0.6963\n",
            "\tCompleted for model:  BERT small #2  K-Fold # 5 F1 score: 0.6364\n",
            "Completed for: ClusterCentroids  with F1 score: 0.6468  Oversampling duration: 0:01:42.995584\n",
            "Completed for  BERT small #2  with results= ['BERT small #2', 0.6294, 0.6756, 0.6468]\n",
            "UnderSampled dataset shape: 488 256\n",
            "\tCompleted for model:  BERT small  K-Fold # 1 F1 score: 0.7299\n",
            "\tCompleted for model:  BERT small  K-Fold # 2 F1 score: 0.7618\n",
            "\tCompleted for model:  BERT small  K-Fold # 3 F1 score: 0.8199\n",
            "\tCompleted for model:  BERT small  K-Fold # 4 F1 score: 0.7946\n",
            "\tCompleted for model:  BERT small  K-Fold # 5 F1 score: 0.7929\n",
            "Completed for: RandomUnderSampler  with F1 score: 0.7798  Oversampling duration: 0:00:00.011459\n",
            "UnderSampled dataset shape: 488 256\n",
            "\tCompleted for model:  BERT small  K-Fold # 1 F1 score: 0.5311\n",
            "\tCompleted for model:  BERT small  K-Fold # 2 F1 score: 0.7564\n",
            "\tCompleted for model:  BERT small  K-Fold # 3 F1 score: 0.8631\n",
            "\tCompleted for model:  BERT small  K-Fold # 4 F1 score: 0.868\n",
            "\tCompleted for model:  BERT small  K-Fold # 5 F1 score: 0.8738\n",
            "Completed for: NearMiss  with F1 score: 0.7785  Oversampling duration: 0:00:01.745892\n",
            "UnderSampled dataset shape: 488 256\n",
            "\tCompleted for model:  BERT small  K-Fold # 1 F1 score: 0.8461\n",
            "\tCompleted for model:  BERT small  K-Fold # 2 F1 score: 0.788\n",
            "\tCompleted for model:  BERT small  K-Fold # 3 F1 score: 0.8769\n",
            "\tCompleted for model:  BERT small  K-Fold # 4 F1 score: 0.7832\n",
            "\tCompleted for model:  BERT small  K-Fold # 5 F1 score: 0.7891\n",
            "Completed for: ClusterCentroids  with F1 score: 0.8167  Oversampling duration: 0:01:40.129687\n",
            "Completed for  BERT small  with results= ['BERT small', 0.7798, 0.7785, 0.8167]\n",
            "UnderSampled dataset shape: 488 768\n",
            "\tCompleted for model:  BERT multi cased  K-Fold # 1 F1 score: 0.7382\n",
            "\tCompleted for model:  BERT multi cased  K-Fold # 2 F1 score: 0.775\n",
            "\tCompleted for model:  BERT multi cased  K-Fold # 3 F1 score: 0.6709\n",
            "\tCompleted for model:  BERT multi cased  K-Fold # 4 F1 score: 0.767\n",
            "\tCompleted for model:  BERT multi cased  K-Fold # 5 F1 score: 0.6836\n",
            "Completed for: RandomUnderSampler  with F1 score: 0.7269  Oversampling duration: 0:00:00.020870\n",
            "UnderSampled dataset shape: 488 768\n",
            "\tCompleted for model:  BERT multi cased  K-Fold # 1 F1 score: 0.6476\n",
            "\tCompleted for model:  BERT multi cased  K-Fold # 2 F1 score: 0.8555\n",
            "\tCompleted for model:  BERT multi cased  K-Fold # 3 F1 score: 0.7729\n",
            "\tCompleted for model:  BERT multi cased  K-Fold # 4 F1 score: 0.7247\n",
            "\tCompleted for model:  BERT multi cased  K-Fold # 5 F1 score: 0.7865\n",
            "Completed for: NearMiss  with F1 score: 0.7574  Oversampling duration: 0:00:05.266867\n",
            "UnderSampled dataset shape: 488 768\n",
            "\tCompleted for model:  BERT multi cased  K-Fold # 1 F1 score: 0.7042\n",
            "\tCompleted for model:  BERT multi cased  K-Fold # 2 F1 score: 0.738\n",
            "\tCompleted for model:  BERT multi cased  K-Fold # 3 F1 score: 0.7727\n",
            "\tCompleted for model:  BERT multi cased  K-Fold # 4 F1 score: 0.7982\n",
            "\tCompleted for model:  BERT multi cased  K-Fold # 5 F1 score: 0.8462\n",
            "Completed for: ClusterCentroids  with F1 score: 0.7719  Oversampling duration: 0:04:18.426377\n",
            "Completed for  BERT multi cased  with results= ['BERT multi cased', 0.7269, 0.7574, 0.7719]\n",
            "UnderSampled dataset shape: 488 768\n",
            "\tCompleted for model:  BERT big  K-Fold # 1 F1 score: 0.8813\n",
            "\tCompleted for model:  BERT big  K-Fold # 2 F1 score: 0.7679\n",
            "\tCompleted for model:  BERT big  K-Fold # 3 F1 score: 0.9068\n",
            "\tCompleted for model:  BERT big  K-Fold # 4 F1 score: 0.8293\n",
            "\tCompleted for model:  BERT big  K-Fold # 5 F1 score: 0.8934\n",
            "Completed for: RandomUnderSampler  with F1 score: 0.8557  Oversampling duration: 0:00:00.021281\n",
            "UnderSampled dataset shape: 488 768\n",
            "\tCompleted for model:  BERT big  K-Fold # 1 F1 score: 0.8356\n",
            "\tCompleted for model:  BERT big  K-Fold # 2 F1 score: 0.8581\n",
            "\tCompleted for model:  BERT big  K-Fold # 3 F1 score: 0.8945\n",
            "\tCompleted for model:  BERT big  K-Fold # 4 F1 score: 0.9493\n",
            "\tCompleted for model:  BERT big  K-Fold # 5 F1 score: 0.9583\n",
            "Completed for: NearMiss  with F1 score: 0.8992  Oversampling duration: 0:00:05.181871\n",
            "UnderSampled dataset shape: 488 768\n",
            "\tCompleted for model:  BERT big  K-Fold # 1 F1 score: 0.9385\n",
            "\tCompleted for model:  BERT big  K-Fold # 2 F1 score: 0.9386\n",
            "\tCompleted for model:  BERT big  K-Fold # 3 F1 score: 0.8966\n",
            "\tCompleted for model:  BERT big  K-Fold # 4 F1 score: 0.8772\n",
            "\tCompleted for model:  BERT big  K-Fold # 5 F1 score: 0.8286\n",
            "Completed for: ClusterCentroids  with F1 score: 0.8959  Oversampling duration: 0:04:12.529488\n",
            "Completed for  BERT big  with results= ['BERT big', 0.8557, 0.8992, 0.8959]\n",
            "UnderSampled dataset shape: 488 300\n",
            "\tCompleted for model:  FastText  K-Fold # 1 F1 score: 0.6632\n",
            "\tCompleted for model:  FastText  K-Fold # 2 F1 score: 0.7967\n",
            "\tCompleted for model:  FastText  K-Fold # 3 F1 score: 0.9049\n",
            "\tCompleted for model:  FastText  K-Fold # 4 F1 score: 0.7701\n",
            "\tCompleted for model:  FastText  K-Fold # 5 F1 score: 0.6719\n",
            "Completed for: RandomUnderSampler  with F1 score: 0.7614  Oversampling duration: 0:00:00.011387\n",
            "UnderSampled dataset shape: 488 300\n",
            "\tCompleted for model:  FastText  K-Fold # 1 F1 score: 0.8286\n",
            "\tCompleted for model:  FastText  K-Fold # 2 F1 score: 0.7779\n",
            "\tCompleted for model:  FastText  K-Fold # 3 F1 score: 0.7213\n",
            "\tCompleted for model:  FastText  K-Fold # 4 F1 score: 0.9585\n",
            "\tCompleted for model:  FastText  K-Fold # 5 F1 score: 0.7777\n",
            "Completed for: NearMiss  with F1 score: 0.8128  Oversampling duration: 0:00:02.028836\n",
            "UnderSampled dataset shape: 488 300\n",
            "\tCompleted for model:  FastText  K-Fold # 1 F1 score: 0.8867\n",
            "\tCompleted for model:  FastText  K-Fold # 2 F1 score: 0.7777\n",
            "\tCompleted for model:  FastText  K-Fold # 3 F1 score: 0.838\n",
            "\tCompleted for model:  FastText  K-Fold # 4 F1 score: 0.8356\n",
            "\tCompleted for model:  FastText  K-Fold # 5 F1 score: 0.7143\n",
            "Completed for: ClusterCentroids  with F1 score: 0.8105  Oversampling duration: 0:01:54.249976\n",
            "Completed for  FastText  with results= ['FastText', 0.7614, 0.8128, 0.8105]\n",
            "Total time elapsed: 0:14:50.128104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelis</th>\n",
              "      <th>RandomUnderSampler</th>\n",
              "      <th>NearMiss</th>\n",
              "      <th>ClusterCentroids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BERT small #2</td>\n",
              "      <td>0.6294</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>0.6468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BERT small</td>\n",
              "      <td>0.7798</td>\n",
              "      <td>0.7785</td>\n",
              "      <td>0.8167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BERT multi cased</td>\n",
              "      <td>0.7269</td>\n",
              "      <td>0.7574</td>\n",
              "      <td>0.7719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BERT big</td>\n",
              "      <td>0.8557</td>\n",
              "      <td>0.8992</td>\n",
              "      <td>0.8959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FastText</td>\n",
              "      <td>0.7614</td>\n",
              "      <td>0.8128</td>\n",
              "      <td>0.8105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Modelis  RandomUnderSampler  NearMiss  ClusterCentroids\n",
              "0     BERT small #2              0.6294    0.6756            0.6468\n",
              "1        BERT small              0.7798    0.7785            0.8167\n",
              "2  BERT multi cased              0.7269    0.7574            0.7719\n",
              "3          BERT big              0.8557    0.8992            0.8959\n",
              "4          FastText              0.7614    0.8128            0.8105"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDK073WeZ9Lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_data.to_csv('2020_05_13_papildinatie_visi_UnderSampling_results.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-sP7WeZehSs",
        "colab_type": "text"
      },
      "source": [
        "<h2>Bāzlīnija</h2>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD2M6btGejM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import text\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiRoBQ-qfLSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_table = []\n",
        "header_row = ['Vārdnīcas izmērs', 'Oversampler', 'Rezultāti']\n",
        "result_table.append(header_row)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4UeTEtLfcOT",
        "colab_type": "code",
        "outputId": "b4ce6b0e-3c27-4e9a-fa26-e51f3d3407c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "print(base_data.shape)\n",
        "base_data.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23391, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>septembrī noslēgt dv līgumu tas pats darba laiks</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>strādās bibliotēka</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kāds darba laiks kab piektdienā lūdzu atbildie...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question  labels\n",
              "0   septembrī noslēgt dv līgumu tas pats darba laiks       2\n",
              "1                                 strādās bibliotēka       2\n",
              "2  kāds darba laiks kab piektdienā lūdzu atbildie...       2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AZI_sAFgAIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col_count = len(base_data.columns)\n",
        "features = base_data['Question'].to_numpy().astype('str')\n",
        "target = base_data['labels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OfkfHkoipmD",
        "colab_type": "code",
        "outputId": "d5ff07b6-f2fe-4adf-ffbe-9e4e7a356bd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_words = 2000\n",
        "# Text pre-processing\n",
        "tokenize = text.Tokenizer(num_words=max_words, char_level=False)                # izveidojam Tokenizer ar noteikto vārdnīcas izmēru\n",
        "tokenize.fit_on_texts(features)                                                 # apmācām Tokenizer uz mūsu datiem\n",
        "X = tokenize.texts_to_matrix(features)                                          # pārveidojam treniņdatus par tekstvienību vektoriem\n",
        "print('Tokenizer done:', max_words, X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizer done: 2000 (23391, 2000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GFuj6hzjLab",
        "colab_type": "text"
      },
      "source": [
        "<h3>ClusterCentroids nav iespējams darbināt ar Bāzlīniju Naive Bayes, jo tā vērtības ir negatīvas</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rhubpMberXp",
        "colab_type": "code",
        "outputId": "80106b11-12e2-4ebd-f01d-fea095ad9b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "exec_start = datetime.datetime.now()\n",
        "n_split = 5                                                                     # at each fold, we use 80% / 20% split\n",
        "indices = range(3)\n",
        "for i, undersampler in zip( indices, (RandomUnderSampler(),\n",
        "                                       NearMiss(),\n",
        "                                       ClusterCentroids()\n",
        "                                        )):\n",
        "  us_name = undersampler.__class__.__name__\n",
        "  date_start    = datetime.datetime.now()                                     # Fiksējam Undersampling sākuma laiku     \n",
        "  X_res, y_res = undersampler.fit_resample(X, target)                         # Veicam UnderSampling\n",
        "  date_end = datetime.datetime.now()                                          # Fiksējam beigu laiku\n",
        "  time_elapsed_us = date_end - date_start                                     # Fiksējam Undersampling patērēto laiku\n",
        "  print('Undersampled dataset shape:', len(X_res), len(X_res[0]))\n",
        "  result_row = []\n",
        "  result_row.append(max_words)\n",
        "  result_row.append(us_name)\n",
        " \n",
        "  f1_scores_naive = []                                                          # Creating an empty array of f1 scores \n",
        "  f1_scores_keras = []\n",
        "  counter = 0\n",
        "  for train_index,test_index in StratifiedKFold(n_split).split(X_res, y_res):\n",
        "    # creating train and test datasets\n",
        "    x_train,x_test=X_res[train_index],X_res[test_index]\n",
        "    y_train,y_test=y_res[train_index],y_res[test_index]\n",
        "\n",
        "    ### Naive Bayes ###\n",
        "    naive_bayes = MultinomialNB()                                               # Izveidojam Naive Bayes modeli\n",
        "    naive_bayes.fit(x_train, y_train)                                           # Trenējam modeli uz treniņdatiem\n",
        "    naive_y_pred = naive_bayes.predict(x_test)\n",
        "    naive_f1_avg = round(f1_score(y_test, naive_y_pred, average='macro'),4)     # Fiksējam Naive Bayes f1 vidējo rezultātu\n",
        "    f1_scores_naive.append(naive_f1_avg)\n",
        "\n",
        "    ### Keras Sequential ###\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(256, activation='relu', input_shape=(max_words,)))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "    model.compile(loss=['sparse_categorical_crossentropy'],\n",
        "                optimizer='adam',\n",
        "                metrics=['sparse_categorical_crossentropy'])\n",
        "    batch_size = 64\n",
        "    epochs = 5\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        verbose=0)\n",
        "    y_pred = model.predict(x_test)                                              # Prasam modelim paredzēt testa datiem kategorijas\n",
        "    keras_y_pred = transformResults(y_pred)                                     # Pārveidojam rezultātus, paņemot ticamāko klasi no varbūtībām\n",
        "    keras_f1_avg = round(f1_score(y_test, keras_y_pred, average='macro'),4)     # Fiksējam Naive Bayes f1 vidējo rezultātu\n",
        "    f1_scores_keras.append(keras_f1_avg)\n",
        "    counter = counter + 1\n",
        "    print('\\tCompleted for vocabulary size:', max_words,' K-Fold #',counter, ' Naive Bayes score:',naive_f1_avg, ' Keras score:',keras_f1_avg)\n",
        "    \n",
        "  #After the K-Fold validation\n",
        "  f1_avg_naive = round(np.mean(f1_scores_naive), 4)\n",
        "  f1_avg_keras = round(np.mean(f1_scores_keras),4)\n",
        "  result_text = str(f1_avg_naive) + '/' + str(f1_avg_keras)\n",
        "  print('Completed for vocabulary size:', max_words,' Naive Bayes/Keras score:',result_text)\n",
        "  result_row.append(result_text)\n",
        "  result_table.append(result_row)\n",
        "#In the very end - fix the execution time\n",
        "exec_end = datetime.datetime.now()\n",
        "exec_elapsed = exec_end - exec_start\n",
        "print('Total time elapsed:', exec_elapsed)\n",
        "\n",
        "# Saglabājam visus rezultātus\n",
        "result_data = pd.DataFrame(result_table[1:], columns=result_table[0])\n",
        "result_data.to_csv('2020_05_13_papildinatie_Bāzlīnija_UnderSampling_results.csv')\n",
        "result_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Undersampled dataset shape: 488 2000\n",
            "\tCompleted for vocabulary size: 2000  K-Fold # 1  Naive Bayes score: 0.8258  Keras score: 0.8546\n",
            "\tCompleted for vocabulary size: 2000  K-Fold # 2  Naive Bayes score: 0.8642  Keras score: 0.9167\n",
            "\tCompleted for vocabulary size: 2000  K-Fold # 3  Naive Bayes score: 0.8224  Keras score: 0.8603\n",
            "\tCompleted for vocabulary size: 2000  K-Fold # 4  Naive Bayes score: 0.812  Keras score: 0.8331\n",
            "\tCompleted for vocabulary size: 2000  K-Fold # 5  Naive Bayes score: 0.8248  Keras score: 0.8155\n",
            "Completed for vocabulary size: 2000  Naive Bayes/Keras score: 0.8298/0.856\n",
            "Undersampled dataset shape: 488 2000\n",
            "\tCompleted for vocabulary size: 2000  K-Fold # 1  Naive Bayes score: 0.9059  Keras score: 0.8836\n",
            "\tCompleted for vocabulary size: 2000  K-Fold # 2  Naive Bayes score: 0.9493  Keras score: 0.9493\n",
            "\tCompleted for vocabulary size: 2000  K-Fold # 3  Naive Bayes score: 0.6618  Keras score: 0.6571\n",
            "\tCompleted for vocabulary size: 2000  K-Fold # 4  Naive Bayes score: 0.5996  Keras score: 0.7824\n",
            "\tCompleted for vocabulary size: 2000  K-Fold # 5  Naive Bayes score: 0.6012  Keras score: 0.4843\n",
            "Completed for vocabulary size: 2000  Naive Bayes/Keras score: 0.7436/0.7513\n",
            "Undersampled dataset shape: 488 2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-233cce21de8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m### Naive Bayes ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mnaive_bayes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                               \u001b[0;31m# Izveidojam Naive Bayes modeli\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mnaive_bayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m                                           \u001b[0;31m# Trenējam modeli uz treniņdatiem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mnaive_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaive_bayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mnaive_f1_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnaive_y_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# Fiksējam Naive Bayes f1 vidējo rezultātu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_effective_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mcheck_non_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[0;34m(X, whom)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
          ]
        }
      ]
    }
  ]
}